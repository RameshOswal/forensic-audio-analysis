{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modulation Spectrograms\n",
    "\n",
    "<b>Overview</b>\n",
    "<p>  The modulation spectrogram is motivated by the need to represent signals that distinguishes between high frequency carrier waves and the low frequency waves that modulate them. In other words, a given signal might be represented by a general form with some fluctuations along its amplitude (1).</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Spectrogram vs. Modulation Spectrogram  </b>\n",
    "<p>In many ways, modulation spectrogram is similar to the STFT spectrogram. The spectrogram is a visual \n",
    "representation of acoustic frequency vs. time information obtained by taking the square of the magnitude of \n",
    "the STFT (1). At a given time, it can tell you what acoustic frequency is present in the signal (with a tradeoff \n",
    "between time and frequency resolution, of course). Similarly, given a frequency, it can tell you what time the \n",
    "frequency appears. The modulation spectrogram, on the other hand, is a representation of acoustic frequency vs \n",
    "modulation frequency. That is, given a modulation frequency, it can tell you what carrier frequencies it modulates \n",
    "and given a carrier acoustic frequency, it can tell you which frequencies modulate it.  </p> \n",
    "<p>Note that &quot;acoustic \n",
    "frequency&quot; refers to the Fourier decomposition of the signal, and can be seen as the carrier signal. \n",
    "The &quot;modulation frequency&quot; is the low frequencysignal that modulates, or alters the amplitude or frequency of, \n",
    "the high frequency carrier signal (2). An example of a comparison between the acoustic frequency vs time (STFT spectrogram) \n",
    "and the acoustic vs modulation frequency is presented below. It represents two simultaneous speakers, one saying &quot;two&quot; and the other saying &quot;dos.&quot; As you can see, the spectrogram is not able to distinguish between the two sounds. The modulation spectrogram, is able to discriminate between the two speakers and isolate the two fundamental pitches and the harmonics (first and aliased) of the speakers (1). </p>\n",
    "<img src=shamma_specgram_vs_modspecgram.png>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The Model</b>\n",
    "<p>Presented below is a simplified version of the transformation used to construct the modulation spectrogram \n",
    "representation (1).</p>\n",
    "<img src=\"shamma_modspecgram_simplified.png\">\n",
    "<p>\n",
    "The input signal is first downsampled to match Kingsbury's implementation, then divided into non-overlapping segments that are processed as individual frames.  The modulation spectrogram is obtained by first selecting the wide frequency bands for using a Gammatone filterbank.  This selects the equally spaced channels of desired acoustic frequencies.  The content in each of these channels is processed into envelope form via a half-wave rectifier, then a lowpass filter.  This envelope can also be obtained via the Hilbert function, and is currently incomplete in my implementation.  Next, this signal is again downsampled to save on computational costs. Each of these envelopes are then normalized, then passed through a complex bandpass filter to capture the slow modulations of the signal.\n",
    "Finally, the log is taken for each envelope and the final signal is thresholded at -30dB.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Previous Attempts</b>\n",
    "<p> This implementation is still a work in progress.  The goal is to successfully obtain the modulation spectrogram of a 10 second audio segment of a boat. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Results </b>\n",
    "\n",
    "<p> The following images are the result of performing FFT on the output of filterbanks. </p>\n",
    "<img src=\"old_files/oldout1.jpg\">\n",
    "<img src=\"old_files/oldout2.jpg\">\n",
    "\n",
    "<p> Later iterations follow Kingsbury's implementation more closely and use Gammatone filters.</p>\n",
    "<img src=\"img.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Shamma, Shihab A.  Joint Acoustic and Modulation Frequency. <i> EURASIP Journal on Applied Signal Processing. </i> http://isdl.ee.washington.edu/projects/icassptutorial/Publications_acoustic_files/atlas-eurasip-2003.pdf\n",
    "2. Maji, P, Ghosh, A, Murty, M, Ghosh, K. Pattern Recognition and Machine Intelligence. <i> 5th International Conference.</i> https://books.google.com/books?id=BAu7BQAAQBAJ&pg=PA135&lpg=PA135&dq=modulation+spectrogram+stft&source=bl&ots=bvzLaOsxdU&sig=2w2YdQFWAbJsalkE2EP5r0tAQqM&hl=en&sa=X&ved=0ahUKEwjK1qThpv7WAhVEwiYKHd03COMQ6AEIQjAF#v=onepage&q=modulation%20spectrogram%20stft&f=false\n",
    "3. Van hamme, Hugo and Baby, Deepak. (2015). <i>Investigating Modulation Spectrogram Features for Deep Neural Network-based Automatic Speech Recognition. </i>\n",
    "4. http://amtoolbox.sourceforge.net/amt-0.9.9/doc/general/modspecgram.php\n",
    "5. Kingsbury, Brian. (1997). <i>Robust speech recognition using the modulation spectrogram</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
